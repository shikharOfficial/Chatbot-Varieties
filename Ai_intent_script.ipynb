{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "HTML_FOLDER_PATH = os.path.join(os.getcwd(), 'DATA')\n",
    "\n",
    "distinct_tags_in_ai_intent_1 = set()\n",
    "distinct_tags_in_ai_intent_2 = set()\n",
    "\n",
    "distinct_tags = {\n",
    "    \"1\": distinct_tags_in_ai_intent_1,\n",
    "    \"2\": distinct_tags_in_ai_intent_2\n",
    "}\n",
    "\n",
    "def fetch_tags(tag: BeautifulSoup, all_tags: List):\n",
    "    if tag.has_attr('ai-intent'):\n",
    "        if tag.decode_contents().strip() != \"\":\n",
    "            ai_intent_value = tag['ai-intent']\n",
    "            tag_name = tag.name\n",
    "            distinct_tags.get(ai_intent_value, set()).add(tag_name)\n",
    "            tag_content = {\n",
    "                'tag': tag_name,\n",
    "                'content': tag.text.strip(),\n",
    "                'ai-intent': ai_intent_value\n",
    "            }\n",
    "            all_tags.append(tag_content)\n",
    "    for child in tag.find_all(recursive=False):\n",
    "        fetch_tags(child, all_tags)\n",
    "\n",
    "def extract_content_from_html(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        all_tags = []\n",
    "        fetch_tags(soup, all_tags)\n",
    "        \n",
    "        grouped_data = defaultdict(list)\n",
    "        for item in all_tags:\n",
    "            tag = item['tag']\n",
    "            content = item['content']\n",
    "            content_with_ai_intent = {\n",
    "                \"content\": content,\n",
    "                \"ai-intent\": item['ai-intent']\n",
    "            }\n",
    "            grouped_data[tag].append(content_with_ai_intent)\n",
    "\n",
    "        return grouped_data\n",
    "    \n",
    "def create_ai_intent_files(grouped_data, file_name):\n",
    "    filtered_data_1 = {\"file_name\": file_name, \"data\": {}}\n",
    "    filtered_data_2 = {\"file_name\": file_name, \"data\": {}}\n",
    "    \n",
    "    for tag, values in grouped_data.items():\n",
    "        filtered_data_1[\"data\"][tag] = [item[\"content\"] for item in values if item[\"ai-intent\"] == \"1\"]\n",
    "        filtered_data_2[\"data\"][tag] = [item[\"content\"] for item in values if item[\"ai-intent\"] == \"2\"]\n",
    "    \n",
    "    filtered_data_1[\"data\"] = {tag: items for tag, items in filtered_data_1[\"data\"].items() if items}\n",
    "    filtered_data_2[\"data\"] = {tag: items for tag, items in filtered_data_2[\"data\"].items() if items}\n",
    "    \n",
    "    return filtered_data_1, filtered_data_2\n",
    "\n",
    "def process_html_files_recursively(folder_path):\n",
    "    ai_intent_1 = []\n",
    "    ai_intent_2 = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.html'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                grouped_data = extract_content_from_html(file_path)\n",
    "                filtered_data_1, filtered_data_2 = create_ai_intent_files(grouped_data, file_name)\n",
    "                ai_intent_1.append(filtered_data_1)\n",
    "                ai_intent_2.append(filtered_data_2)\n",
    "                \n",
    "    with open('ai-intent_1.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(ai_intent_1, json_file, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    with open('ai-intent_2.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(ai_intent_2, json_file, indent=4, ensure_ascii=False)\n",
    "                \n",
    "process_html_files_recursively(HTML_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'div', 'li', 'ol', 'p', 'section', 'span', 'table', 'tbody', 'td', 'th', 'ul'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_tags['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'Changing_Password.html',\n",
       "  'total_contents': [{'tag': 'h1', 'content': 'Changing Password'}]},\n",
       " {'file_name': 'Retrieving_Password.html',\n",
       "  'total_contents': [{'tag': 'h1', 'content': 'Retrieving Password'}]},\n",
       " {'file_name': 'Modifying_User_Preferences.html',\n",
       "  'total_contents': [{'tag': 'h1', 'content': 'Modifying User Preferences'}]},\n",
       " {'file_name': 'Engage_Home.html',\n",
       "  'total_contents': [{'tag': 'h1', 'content': 'Engage Home'},\n",
       "   {'tag': 'p',\n",
       "    'content': 'The Home page displays the\\n                    list of all available campaigns with their statuses and enables the agency users to view a summary\\n                    of the campaign details. The project campaigns have the following statuses:'},\n",
       "   {'tag': 'p',\n",
       "    'content': 'The Search campaigns field\\n                    enables you to search for appropriate campaigns and view the details of projects associated with\\n                    them.'},\n",
       "   {'tag': 'p',\n",
       "    'content': 'The Sort by drop-down list\\n                    enables you to sort the list of campaigns displayed. The options to sort are as follows:'},\n",
       "   {'tag': 'p',\n",
       "    'content': 'The Filter option enables you\\n                    to filter the campaigns based on the following:'},\n",
       "   {'tag': 'table',\n",
       "    'content': 'Status\\nDescription\\n\\n\\n\\n\\nDRAFT\\n\\n\\nDuring campaign creation, the status of the campaign is in\\n                                                the DRAFT status.\\nWhen a campaign in PUBLISHED status is withdrawn, the status of\\n                                                the campaign is changed to the DRAFT status.\\n\\n\\n\\n\\nPUBLISHED\\nAfter the user\\n                                        creates and publishes the campaign for general public participation, the\\n                                        campaign is changed to PUBLISHED\\n                                        status.\\n\\n\\nACCEPTING COMMENTS\\n                                    \\nA campaign will\\n                                        start receiving comments from the general public during a specified commenting\\n                                        period. The published campaigns during this commenting period will have the\\n                                        ACCEPTING COMMENTS status. Once\\n                                        the commenting period ends, the status of the campaign changes to COMPLETED status.\\n\\n\\nWITHDRAWN\\nWhen you withdraw\\n                                        an ongoing campaign that is in ACCEPTING COMMENTS status, then the status of the\\n                                        campaign is changed to the WITHDRAWN status.\\n\\n\\nCOMPLETED\\nAfter the\\n                                        commenting period is complete, the campaign is changed to COMPLETED status.\\n\\n\\nCLOSED\\nAfter all the\\n                                        analysis for the completed campaign is done, the status of the campaign can be\\n                                        changed to CLOSED status.'}]}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"ai-intent_1.json\", \"r\") as file:\n",
    "    ai_intent_1_file = json.load(file)\n",
    "    \n",
    "with open(\"ai-intent_2.json\", \"r\") as file:\n",
    "    ai_intent_2_file = json.load(file)\n",
    "\n",
    "def get_contexts():           \n",
    "    priorities = {\n",
    "        \"1\": [\"h1\", \"h2\", \"h3\", \"ul\", \"ol\", \"li\"],\n",
    "        \"2\": [\"p\", \"table\", \"note\"]\n",
    "    }     \n",
    "    \n",
    "    total_contents = []\n",
    "    for ai_intent_value, tag_list in priorities.items():\n",
    "        for tag in tag_list:\n",
    "            if tag in distinct_tags[ai_intent_value]:\n",
    "                content = read_tag_contents(tag, ai_intent_value)\n",
    "                total_contents.extend(content)\n",
    "                \n",
    "    grouped_contents = defaultdict(list)\n",
    "    \n",
    "    for obj in total_contents:\n",
    "        file_name, tag, content = list(obj.values())\n",
    "        grouped_contents[file_name].append({\"tag\": tag, \"content\": content})\n",
    "    \n",
    "    result = [{\"file_name\": file_name, \"total_contents\": contents} for file_name, contents in grouped_contents.items()]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def read_tag_contents(tag_name, ai_intent_value):\n",
    "    ai_intent_file_name = ai_intent_1_file if ai_intent_value == \"1\" else ai_intent_2_file\n",
    "    \n",
    "    return [{\"file_name\": obj['file_name'], \"tag\": tag, \"content\": content} \n",
    "            for obj in ai_intent_file_name \n",
    "            for tag, content_list in obj['data'].items() \n",
    "            if tag == tag_name \n",
    "            for content in content_list\n",
    "            ]\n",
    "\n",
    "AVAILABLE_CONTEXTS = get_contexts()\n",
    "AVAILABLE_CONTEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import wraps\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def get_filtered_keywords(user_query):\n",
    "    query_embedding = model.encode([user_query])\n",
    "    keywords_embeddings = model.encode([keyword['content'] for keyword in AVAILABLE_CONTEXTS])\n",
    "\n",
    "    similarities = cosine_similarity(query_embedding, keywords_embeddings)\n",
    "\n",
    "    similarity_pairs = list(zip(AVAILABLE_CONTEXTS, similarities[0]))\n",
    "\n",
    "    sorted_keywords = sorted(similarity_pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    filtered_keywords = [keyword for keyword, score in sorted_keywords if score > threshold]\n",
    "    \n",
    "    return filtered_keywords\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def clean_text_decorator(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        return clean_text(result)\n",
    "    return wrapper\n",
    "\n",
    "@clean_text_decorator\n",
    "def get_relevent_context_from_files(contexts):\n",
    "    data = []\n",
    "    file_names = [context['file_name']  for context in contexts]\n",
    "    \n",
    "    body_contents = \"/n/n\".join([obj['data']['body'][0] for obj in ai_intent_1_file if obj['file_name'] in file_names])\n",
    "    return body_contents\n",
    "\n",
    "def get_contexts_wrapper(user_query):\n",
    "    filtered_keywords = get_filtered_keywords(user_query)\n",
    "    print(filtered_keywords)\n",
    "    contexts = get_relevent_context_from_files(filtered_keywords)\n",
    "    return contexts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/metapercept/.cache/huggingface/token\n",
      "Login successful\n",
      "[{'file_name': 'Modifying_User_Preferences.html', 'content': 'Modifying User Preferences'}, {'file_name': 'User_Management.html', 'content': 'User Management'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nIn the given context, User Preferences is a page where you can update personal information of your account such as First Name, Last Name, Department, and Designation. You cannot change the email address.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "prompt = \"\"\"Answer the question based on the following context. If you don't know the answer, just say that you don't know, don't try to make up an answer. Ensure the answer is concise and to the point.\n",
    "\n",
    "###Context: {context}\n",
    "###Question: {question}\n",
    "\n",
    "###Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate(template=prompt, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id,temperature=0.01,huggingfacehub_api_token='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')\n",
    "\n",
    "user_query = \"user preference\"\n",
    "contexts = get_contexts_wrapper(user_query)\n",
    "\n",
    "formatted_prompt = prompt.format(context=contexts, question=user_query)\n",
    "\n",
    "response = llm(formatted_prompt)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
